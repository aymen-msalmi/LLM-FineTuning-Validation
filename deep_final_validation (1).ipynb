{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdelwahedSouiid/Transformers/blob/aymen/Transforming%20Amazon%20Product%20Reviews%20into%20Insights%3A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd9Pq3Za0vLX"
      },
      "source": [
        "<div style=\"text-align: center;\">\n",
        "    <strong>Transforming Amazon Product Reviews into Insights: A Sentiment Analysis Approach Using Transformer Models</strong>\n",
        "</div>\n",
        "\n",
        "## Introduction\n",
        "This notebook focuses on sentiment classification of Amazon product reviews using transformer models. The objective is to analyze customer sentiments and derive insights from product reviews. We will utilize BERT, RoBERTa, and DistilBERT for this task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mwNH-1L0vLX"
      },
      "source": [
        "## Dataset Overview\n",
        "In this section, we load the Amazon product reviews dataset. The dataset contains user reviews, product IDs, scores, and additional metadata. We will preprocess this data for sentiment analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qfkOwRejtmD4",
        "outputId": "8f65e577-05ac-463f-fe5c-1540a548102d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "_gz53SPetsd8",
        "outputId": "d603febf-00f9-4270-b6d5-ef650d200bf4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c8a2b760-73e1-419b-9f0e-cc46f2707890\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c8a2b760-73e1-419b-9f0e-cc46f2707890\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"aymenmsalmi\",\"key\":\"ffe2251aa4fd313d1654afdec8753d14\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Choose your kaggle.json file to upload\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2r-6EKfetu3D",
        "outputId": "0bcaed66-dec6-4f41-c4c1-a24a7f7e7660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/arhamrumi/amazon-product-reviews\n",
            "License(s): CC0-1.0\n",
            "Downloading amazon-product-reviews.zip to /content\n",
            " 85% 97.0M/115M [00:00<00:00, 167MB/s]\n",
            "100% 115M/115M [00:00<00:00, 143MB/s] \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d arhamrumi/amazon-product-reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yL3JkJW6t4x5",
        "outputId": "df48d953-986f-4cad-ced0-e3ad6c9cca0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  amazon-product-reviews.zip\n",
            "  inflating: Reviews.csv             \n"
          ]
        }
      ],
      "source": [
        "!unzip amazon-product-reviews.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHcArrBq0vLZ"
      },
      "source": [
        "# Load and Explore Data\n",
        "First, we will load the dataset and take a quick look at the first few rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "X5JaJvmNt7Am",
        "outputId": "84a68604-3c22-4f48-f847-e86deb7c3c6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id   ProductId          UserId                      ProfileName  \\\n",
              "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
              "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
              "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
              "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
              "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
              "\n",
              "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                     1                       1      5  1303862400   \n",
              "1                     0                       0      1  1346976000   \n",
              "2                     1                       1      4  1219017600   \n",
              "3                     3                       3      2  1307923200   \n",
              "4                     0                       0      5  1350777600   \n",
              "\n",
              "                 Summary                                               Text  \n",
              "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
              "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
              "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
              "4            Great taffy  Great taffy at a great price.  There was a wid...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d88ec7a-7317-466c-a755-9b2f059d1f46\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d88ec7a-7317-466c-a755-9b2f059d1f46')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5d88ec7a-7317-466c-a755-9b2f059d1f46 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5d88ec7a-7317-466c-a755-9b2f059d1f46');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0a40a70-b536-48b3-b4ae-ed1c97942529\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0a40a70-b536-48b3-b4ae-ed1c97942529')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0a40a70-b536-48b3-b4ae-ed1c97942529 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset (replace 'your_file.csv' with the actual file name)\n",
        "df = pd.read_csv('/content/Reviews.csv')  # Check the extracted files for the correct filename\n",
        "df.head()  # Display the first few rows\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: chose 500 rows assuring that the text and summary columns are not empty\n",
        "\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming the code to upload kaggle.json and download/unzip the dataset is already executed\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/Reviews.csv')\n",
        "\n",
        "# Filter out rows with empty 'Text' or 'Summary' columns\n",
        "df_filtered = df.dropna(subset=['Text', 'Summary'])\n",
        "\n",
        "# Sample 500 rows\n",
        "df_sampled = df_filtered.sample(n=500, random_state=42) # random_state for reproducibility\n",
        "\n",
        "# Now df_sampled contains 500 rows with non-empty 'Text' and 'Summary' columns\n",
        "df_sampled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "Q-GjUR_M4Qc7",
        "outputId": "bf34abaa-2c38-453a-c610-52589e1c8647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Id   ProductId          UserId                        ProfileName  \\\n",
              "41434    41435  B0088YBUOU  A16O0S1QROXGJM              Amy in SC \"Amy in SC\"   \n",
              "209481  209482  B000Q75354  A37V5C3TXIBIHT                     Martin Dulberg   \n",
              "247306  247307  B000EOXQS0  A28NR6KKJGHQXH  Virginia A. Mashensky \"photo nut\"   \n",
              "80089    80090  B0000D9589   AJBVY9K7D1AZ4                        Mark Gatzke   \n",
              "218580  218581  B000UPNK9S  A2G8OM5IXSG97Q                          gabbersib   \n",
              "\n",
              "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "41434                     10                      11      4  1141516800   \n",
              "209481                     1                       3      4  1265414400   \n",
              "247306                     0                       0      5  1350345600   \n",
              "80089                      7                       7      4  1177027200   \n",
              "218580                     0                       0      2  1314403200   \n",
              "\n",
              "                                                Summary  \\\n",
              "41434                                     I like these!   \n",
              "209481                 Good but subjectively not 5 star   \n",
              "247306         Lipton Cup A Soup, Spring Vegetable.4 oz   \n",
              "80089   Suited to its purpose, if not quite its goal...   \n",
              "218580                               Tastes artificial!   \n",
              "\n",
              "                                                     Text  \n",
              "41434   These are actually very tasty.  Pure potatoes ...  \n",
              "209481  I realize that taste is a matter of personal p...  \n",
              "247306  This is one of my Favorite cup of soup choices...  \n",
              "80089   If you like the classic taste of a good margar...  \n",
              "218580  I was willing to give this a chance even after...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4bd9a307-0769-4147-a476-d081028991d0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41434</th>\n",
              "      <td>41435</td>\n",
              "      <td>B0088YBUOU</td>\n",
              "      <td>A16O0S1QROXGJM</td>\n",
              "      <td>Amy in SC \"Amy in SC\"</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>1141516800</td>\n",
              "      <td>I like these!</td>\n",
              "      <td>These are actually very tasty.  Pure potatoes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209481</th>\n",
              "      <td>209482</td>\n",
              "      <td>B000Q75354</td>\n",
              "      <td>A37V5C3TXIBIHT</td>\n",
              "      <td>Martin Dulberg</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1265414400</td>\n",
              "      <td>Good but subjectively not 5 star</td>\n",
              "      <td>I realize that taste is a matter of personal p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247306</th>\n",
              "      <td>247307</td>\n",
              "      <td>B000EOXQS0</td>\n",
              "      <td>A28NR6KKJGHQXH</td>\n",
              "      <td>Virginia A. Mashensky \"photo nut\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350345600</td>\n",
              "      <td>Lipton Cup A Soup, Spring Vegetable.4 oz</td>\n",
              "      <td>This is one of my Favorite cup of soup choices...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80089</th>\n",
              "      <td>80090</td>\n",
              "      <td>B0000D9589</td>\n",
              "      <td>AJBVY9K7D1AZ4</td>\n",
              "      <td>Mark Gatzke</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1177027200</td>\n",
              "      <td>Suited to its purpose, if not quite its goal...</td>\n",
              "      <td>If you like the classic taste of a good margar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218580</th>\n",
              "      <td>218581</td>\n",
              "      <td>B000UPNK9S</td>\n",
              "      <td>A2G8OM5IXSG97Q</td>\n",
              "      <td>gabbersib</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1314403200</td>\n",
              "      <td>Tastes artificial!</td>\n",
              "      <td>I was willing to give this a chance even after...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bd9a307-0769-4147-a476-d081028991d0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4bd9a307-0769-4147-a476-d081028991d0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4bd9a307-0769-4147-a476-d081028991d0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1953acfb-de67-4f55-b34d-06ac316eb1d7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1953acfb-de67-4f55-b34d-06ac316eb1d7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1953acfb-de67-4f55-b34d-06ac316eb1d7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_sampled",
              "summary": "{\n  \"name\": \"df_sampled\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"Id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 162652,\n        \"min\": 875,\n        \"max\": 567591,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          27611,\n          350706,\n          445586\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ProductId\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 487,\n        \"samples\": [\n          \"B002QWHJOU\",\n          \"B000FDKQII\",\n          \"B003M5XJ12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UserId\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 497,\n        \"samples\": [\n          \"A2X2M3UPUFAW5G\",\n          \"AQUWZQCBF1KGO\",\n          \"AMBP2EK9W5N33\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ProfileName\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 497,\n        \"samples\": [\n          \"jollyxian\",\n          \"Richard Lewis\",\n          \"katie\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HelpfulnessNumerator\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 28,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          10,\n          2,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HelpfulnessDenominator\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 30,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          11,\n          25,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46569322,\n        \"min\": 1141516800,\n        \"max\": 1351209600,\n        \"num_unique_values\": 419,\n        \"samples\": [\n          1239235200,\n          1323993600,\n          1346198400\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 488,\n        \"samples\": [\n          \"great treat! not too smelly\",\n          \"Pretty darn good... for just coffee.\",\n          \"One pouch had off taste and had to be thrown\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 498,\n        \"samples\": [\n          \"I can't give these a 5 because the ingredients show they are very processed.  I'm not sure how healthy they are.<br /><br />But the taste is great - very hot  - like about a nuclear on the Zaxby's scale.  If you like hot wings, you'll like these.  Be prepared to not be able to leave them alone.  When my husband buys a bag, we sit there and eat them until they are gone.  Also, have something to drink handy!\",\n          \"These are the worst tasting BBQ Vienna sausages, no wonder the price was cheaper..<br />Recommend Armour only..sorry LIBBYs, this is not that great\",\n          \"Flavor is ok but product was melted by the time it was delivered. It was messy to eat crumbling all over. Won't buy again because of price increase. There are other bars out there that are cheaper.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EJ4SuTqk8isJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Verify that the filtered dataframe does not contain empty values in the specified columns.\n",
        "empty_text_count_filtered = df_sampled['Text'].isnull().sum()\n",
        "empty_summary_count_filtered = df_sampled['Summary'].isnull().sum()\n",
        "\n",
        "print(f\"Number of empty values in 'Text' column after filtering: {empty_text_count_filtered}\")\n",
        "print(f\"Number of empty values in 'Summary' column after filtering: {empty_summary_count_filtered}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_ZMZdEX4cT6",
        "outputId": "4d0befab-64d8-492d-d08e-aa3242bc8ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of empty values in 'Text' column after filtering: 0\n",
            "Number of empty values in 'Summary' column after filtering: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sampled.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSMeM_4V8lUC",
        "outputId": "950cf5b5-f737-4887-886f-091c11f3812c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: just select the text and the summar colym only\n",
        "\n",
        "# Assuming df_sampled is already defined as in the previous code\n",
        "\n",
        "# Select only the 'Text' and 'Summary' columns\n",
        "selected_df = df_sampled[['Text', 'Summary']]\n",
        "\n",
        "selected_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "mPgXaV6v8u_x",
        "outputId": "be364f01-f62b-4d5a-d004-79703c385455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     Text  \\\n",
              "41434   These are actually very tasty.  Pure potatoes ...   \n",
              "209481  I realize that taste is a matter of personal p...   \n",
              "247306  This is one of my Favorite cup of soup choices...   \n",
              "80089   If you like the classic taste of a good margar...   \n",
              "218580  I was willing to give this a chance even after...   \n",
              "...                                                   ...   \n",
              "120391  I had tried this Cappucino in a package of a v...   \n",
              "169731  A cookie review may initially seem superfluous...   \n",
              "206578  These dry chews help scrape teeth clean and he...   \n",
              "400201  I received this coffee drink from Amazon and w...   \n",
              "547043  This coffee is very strong tasting. We cut it ...   \n",
              "\n",
              "                                                  Summary  \n",
              "41434                                       I like these!  \n",
              "209481                   Good but subjectively not 5 star  \n",
              "247306           Lipton Cup A Soup, Spring Vegetable.4 oz  \n",
              "80089     Suited to its purpose, if not quite its goal...  \n",
              "218580                                 Tastes artificial!  \n",
              "...                                                   ...  \n",
              "120391                             Grove Square Cappucino  \n",
              "169731  Cookie Crunch Lost in Peanut Butter and Fudge ...  \n",
              "206578                               Fresh  Canine Breath  \n",
              "400201                                             coffee  \n",
              "547043                                      Great tasting  \n",
              "\n",
              "[500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c6593e7-ca78-482e-97da-113e50f3fd4d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41434</th>\n",
              "      <td>These are actually very tasty.  Pure potatoes ...</td>\n",
              "      <td>I like these!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209481</th>\n",
              "      <td>I realize that taste is a matter of personal p...</td>\n",
              "      <td>Good but subjectively not 5 star</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247306</th>\n",
              "      <td>This is one of my Favorite cup of soup choices...</td>\n",
              "      <td>Lipton Cup A Soup, Spring Vegetable.4 oz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80089</th>\n",
              "      <td>If you like the classic taste of a good margar...</td>\n",
              "      <td>Suited to its purpose, if not quite its goal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218580</th>\n",
              "      <td>I was willing to give this a chance even after...</td>\n",
              "      <td>Tastes artificial!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120391</th>\n",
              "      <td>I had tried this Cappucino in a package of a v...</td>\n",
              "      <td>Grove Square Cappucino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169731</th>\n",
              "      <td>A cookie review may initially seem superfluous...</td>\n",
              "      <td>Cookie Crunch Lost in Peanut Butter and Fudge ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206578</th>\n",
              "      <td>These dry chews help scrape teeth clean and he...</td>\n",
              "      <td>Fresh  Canine Breath</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400201</th>\n",
              "      <td>I received this coffee drink from Amazon and w...</td>\n",
              "      <td>coffee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>547043</th>\n",
              "      <td>This coffee is very strong tasting. We cut it ...</td>\n",
              "      <td>Great tasting</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows  2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c6593e7-ca78-482e-97da-113e50f3fd4d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c6593e7-ca78-482e-97da-113e50f3fd4d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c6593e7-ca78-482e-97da-113e50f3fd4d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3459eb9f-0600-4f75-9a98-a88167cd003f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3459eb9f-0600-4f75-9a98-a88167cd003f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3459eb9f-0600-4f75-9a98-a88167cd003f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a151f3ab-d930-4ec2-9310-82b3d410f762\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('selected_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a151f3ab-d930-4ec2-9310-82b3d410f762 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('selected_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "selected_df",
              "summary": "{\n  \"name\": \"selected_df\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 498,\n        \"samples\": [\n          \"I can't give these a 5 because the ingredients show they are very processed.  I'm not sure how healthy they are.<br /><br />But the taste is great - very hot  - like about a nuclear on the Zaxby's scale.  If you like hot wings, you'll like these.  Be prepared to not be able to leave them alone.  When my husband buys a bag, we sit there and eat them until they are gone.  Also, have something to drink handy!\",\n          \"These are the worst tasting BBQ Vienna sausages, no wonder the price was cheaper..<br />Recommend Armour only..sorry LIBBYs, this is not that great\",\n          \"Flavor is ok but product was melted by the time it was delivered. It was messy to eat crumbling all over. Won't buy again because of price increase. There are other bars out there that are cheaper.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 488,\n        \"samples\": [\n          \"great treat! not too smelly\",\n          \"Pretty darn good... for just coffee.\",\n          \"One pouch had off taste and had to be thrown\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWHxu6Pm7ybJ",
        "outputId": "2c0dc660-3eda-4584-a07d-23e4cdb1c7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YzlTZyMW7eH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "POrjSPEL5gRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Prompt Engineering"
      ],
      "metadata": {
        "id": "8LUP_nAn5grh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell sets up the necessary libraries and functions for text summarization using a pre-trained T5 model. Below is an overview of what each step accomplishes:\n",
        "\n",
        "- **Library Imports**: The `transformers` library is imported for accessing the T5 model and tokenizer, and `torch` is used for tensor operations.\n",
        "- **Model Initialization**: The `t5-small` pre-trained model and tokenizer are loaded from Hugging Face, enabling efficient input text processing and summary generation.\n",
        "- **Function Creation**: A function named `generate_summary_for_one` is defined to:\n",
        "  - Add a \"summarize:\" prefix to the input text.\n",
        "  - Encode the input text and pass it to the model.\n",
        "  - Generate a concise summary using beam search for improved output quality.\n",
        "- **Error Handling**: The function includes a `try-except` block to gracefully manage any issues that might occur during the summarization process.\n",
        "\n",
        "The function is then applied to the first entry of a DataFrame (`selected_df`) to demonstrate how it can generate a sample summary."
      ],
      "metadata": {
        "id": "iafZ_-5LowN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary library if not already installed\n",
        "# !pip install transformers\n",
        "\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# Load pre-trained T5 model and tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "\n",
        "# Function to generate a summary with a prompt for a single text\n",
        "def generate_summary_for_one(text, max_length=50, min_length=25):\n",
        "    try:\n",
        "        # Add a prompt to the input text\n",
        "        prompted_text = f\"summarize: {text}\"\n",
        "\n",
        "        # Encode the input with proper handling for truncation and tensor type\n",
        "        input_ids = tokenizer.encode(prompted_text, return_tensors=\"pt\", padding=\"longest\", truncation=True, max_length=512)\n",
        "\n",
        "        # Generate summary with the model\n",
        "        summary_ids = model.generate(input_ids, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "\n",
        "        # Decode and return the summary\n",
        "        return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "# Select the first item from the 'Text' and 'Summary' columns of selected_df\n",
        "first_text = selected_df['Text'].iloc[0]  # Ensure that selected_df has been created with the relevant data\n",
        "original_summary = selected_df['Summary'].iloc[0]\n",
        "\n",
        "# Generate the summary\n",
        "predicted_summary = generate_summary_for_one(first_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "DcepC3CR91PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original text, original summary, and generated summary\n",
        "print(\"Original Text:\\n\", first_text)\n",
        "print(\"\\nOriginal Summary:\\n\", original_summary)\n",
        "print(\"\\nGenerated Summary:\\n\", predicted_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DgCzjSl91MY",
        "outputId": "b1de7132-c098-44e3-8306-5b46f965fcf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " These are actually very tasty.  Pure potatoes with a great texture and no nasty filler \"stuff.\"  No bacon, no cheese...just tasty potatoes.  They cook well in either the oven or microwave.  I add a touch of either salt & pepper or fajita seasoning to spice it up.  I rated 4 out of 5 stars because they could be a bit bigger portion.  However, this item is a fairly good value for the money.\n",
            "\n",
            "Original Summary:\n",
            " I like these!\n",
            "\n",
            "Generated Summary:\n",
            " pure potatoes with a great texture and no nasty filler \"stuff\" they cook well in either the oven or microwave. this item is a fairly good value for money.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Tuning"
      ],
      "metadata": {
        "id": "A60CDV3f-yl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-Tuning and Prompt-Based Text Summarization with T5\n",
        "\n",
        "In this cell, we set up and apply a custom approach for generating text summaries using a pre-trained T5 model, with optional support for fine-tuning prompt embeddings. Below is an explanation of each step:\n",
        "\n",
        "- **Library Imports**: Essential libraries such as `transformers` and `torch` are imported. The `T5Tokenizer`, `T5ForConditionalGeneration`, and `T5Config` classes from `transformers` are used for tokenization and model interaction.\n",
        "\n",
        "- **Model Initialization**: The `t5-small` model and tokenizer are loaded from Hugging Face's model repository, enabling the transformation of input text into a summary.\n",
        "\n",
        "- **Custom Function for Generating Summaries**:\n",
        "  - The `generate_summary_with_learned_prompt` function is defined to handle input text and integrate optional prompt embeddings.\n",
        "  - **Prompt Embedding**: If provided, the function incorporates a learned prompt embedding with the input. Otherwise, a default text-based prompt (`\"summarize:\"`) is used.\n",
        "  - The function encodes the input text, generates a summary using beam search for improved results, and decodes the output for readability.\n",
        "\n",
        "- **Example Usage**:\n",
        "  - The code extracts the first entry from a DataFrame (`selected_df`) for testing.\n",
        "  - A placeholder (`None`) for prompt embedding is used to demonstrate how the function works with or without learned prompts.\n",
        "  - The generated summary is printed along with the original text and dataset-provided summary for comparison.\n",
        "\n",
        "This approach demonstrates a way to enhance model performance by using prompt tuning, a technique that can fine-tune the input for better results in NLP tasks.\n"
      ],
      "metadata": {
        "id": "Z5R9eLMKpt2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary library if not already installed\n",
        "# !pip install transformers\n",
        "\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
        "import torch\n",
        "\n",
        "# Load pre-trained T5 model and tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "\n",
        "# Prepare a function to fine-tune prompt embeddings (simulated approach)\n",
        "def generate_summary_with_learned_prompt(text, prompt_embedding=None, max_length=50, min_length=25):\n",
        "    try:\n",
        "        # If a prompt embedding is provided, integrate it into the input\n",
        "        if prompt_embedding:\n",
        "            input_ids = torch.cat((prompt_embedding, tokenizer.encode(text, return_tensors=\"pt\", truncation=True, max_length=512)), dim=-1)\n",
        "        else:\n",
        "            # Default to a fixed textual prompt\n",
        "            prompted_text = f\"summarize: {text}\"\n",
        "            input_ids = tokenizer.encode(prompted_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "        # Generate summary with the model\n",
        "        summary_ids = model.generate(input_ids, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "\n",
        "        # Decode and return the summary\n",
        "        return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "# Select the first item from the 'Text' and 'Summary' columns of selected_df\n",
        "first_text = selected_df['Text'].iloc[0]  # Ensure that selected_df has been created with the relevant data\n",
        "original_summary = selected_df['Summary'].iloc[0]\n",
        "\n",
        "# Simulate prompt embedding (for demonstration purposes)\n",
        "# In real scenarios, this would involve training a continuous embedding\n",
        "prompt_embedding = None  # Placeholder for learned embeddings if available\n",
        "\n",
        "# Generate the summary with prompt tuning (simulated)\n",
        "predicted_summary = generate_summary_with_learned_prompt(first_text, prompt_embedding=prompt_embedding)\n",
        "\n",
        "# Print the original text, original summary, and generated summary\n",
        "print(\"Original Text:\\n\", first_text)\n",
        "print(\"\\nOriginal Summary:\\n\", original_summary)\n",
        "print(\"\\nGenerated Summary with Prompt Tuning:\\n\", predicted_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bafsQuD5jqi",
        "outputId": "8e6e01fb-63c3-4928-b12e-fc7b22ece48b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " These are actually very tasty.  Pure potatoes with a great texture and no nasty filler \"stuff.\"  No bacon, no cheese...just tasty potatoes.  They cook well in either the oven or microwave.  I add a touch of either salt & pepper or fajita seasoning to spice it up.  I rated 4 out of 5 stars because they could be a bit bigger portion.  However, this item is a fairly good value for the money.\n",
            "\n",
            "Original Summary:\n",
            " I like these!\n",
            "\n",
            "Generated Summary with Prompt Tuning:\n",
            " pure potatoes with a great texture and no nasty filler \"stuff\" they cook well in either the oven or microwave. this item is a fairly good value for money.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Soft Prompts for Enhanced Summarization with T5\n",
        "\n",
        "This cell demonstrates how to set up and train soft prompts for enhancing the performance of a pre-trained T5 model in a controlled manner. Soft prompts are trainable embeddings that guide the model without altering its original weights. Here's an overview of the code:\n",
        "\n",
        "- **Library Imports**: `torch`, `nn` (for neural network operations), and components from `transformers` are imported for model loading, optimization, and training.\n",
        "\n",
        "- **Model and Tokenizer Loading**:\n",
        "  - The `T5Tokenizer` and `T5ForConditionalGeneration` are loaded from the Hugging Face library to process input text and generate summaries.\n",
        "  \n",
        "- **Freezing Model Weights**:\n",
        "  - The model weights are frozen using `param.requires_grad = False` to ensure that only the soft prompts are trained while the original model parameters remain unchanged. This allows for efficient training with minimal adjustments to the pre-trained model.\n",
        "\n",
        "- **Creating Trainable Soft Prompt Embeddings**:\n",
        "  - A soft prompt of length 20 is defined, with each embedding having a size matching the model's hidden state (`embedding_size`).\n",
        "  - `nn.Parameter` initializes these embeddings as trainable parameters with random values.\n",
        "  \n",
        "- **Optimizer Initialization**:\n",
        "  - An `Adam` optimizer is set up specifically to train the soft prompt embeddings with a learning rate of `1e-3`.\n",
        "\n",
        "This approach leverages prompt tuning, a technique that fine-tunes input prompts to guide the model more effectively for specific tasks without modifying the core model weights.\n"
      ],
      "metadata": {
        "id": "Xgx-1_ZnyBhm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r7AkGXev_S2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "\n",
        "# Freeze the model weights to train only the soft prompts\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Create trainable soft prompt embeddings\n",
        "soft_prompt_length = 20  # Length of the soft prompt\n",
        "embedding_size = model.config.d_model  # Size of the model's hidden state\n",
        "soft_prompts = nn.Parameter(torch.randn(soft_prompt_length, embedding_size, requires_grad=True))\n",
        "\n",
        "# Initialize the optimizer for soft prompts\n",
        "optimizer = torch.optim.Adam([soft_prompts], lr=1e-3)\n"
      ],
      "metadata": {
        "id": "kBnatXNc5jnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Soft Prompts with T5 for Text Summarization\n",
        "\n",
        "This cell provides a comprehensive example of how to fine-tune trainable soft prompts for text summarization using the T5 model. The following steps are included:\n",
        "\n",
        "- **Library Installation**:\n",
        "  - The `transformers` library is installed to ensure that all necessary components for model loading and training are available.\n",
        "\n",
        "- **Library Imports**:\n",
        "  - `torch` and `nn` from PyTorch are imported for tensor operations and neural network components.\n",
        "  - `T5ForConditionalGeneration` and `T5Tokenizer` from `transformers` are imported for working with the pre-trained T5 model and tokenizer.\n",
        "\n",
        "- **Model and Tokenizer Loading**:\n",
        "  - The `t5-small` model and tokenizer are loaded from Hugging Face's model hub to handle text input and output for summarization.\n",
        "\n",
        "- **Freezing Model Weights**:\n",
        "  - The weights of the T5 model are frozen (`param.requires_grad = False`) so that only the newly added soft prompts are trained, preserving the original model's parameters.\n",
        "\n",
        "- **Creating Trainable Soft Prompts**:\n",
        "  - A soft prompt of length 20 with embedding vectors matching the model's hidden state size is created and initialized as a trainable `nn.Parameter`.\n",
        "  \n",
        "- **Optimizer Initialization**:\n",
        "  - An `Adam` optimizer is configured to update only the soft prompt embeddings with a learning rate of `1e-3`.\n",
        "\n",
        "- **Training Data Preparation**:\n",
        "  - Training data is constructed as a list of input and target summary pairs from a DataFrame (`selected_df`).\n",
        "\n",
        "- **Training Loop**:\n",
        "  - The model is trained for 2 epochs, and for each input text, the soft prompts are combined with the input embeddings.\n",
        "  - The `model.get_input_embeddings()` method retrieves the embeddings for the input IDs, which are concatenated with the soft prompt tensor.\n",
        "  - The model's `forward` method processes the combined tensor and computes the loss using the provided target summary.\n",
        "  - The optimizer updates the soft prompts based on the computed gradients, and the average loss is printed at the end of each epoch to monitor training progress.\n",
        "\n",
        "- **Completion Message**:\n",
        "  - The code prints \"Training completed.\" once the training loop finishes.\n",
        "\n",
        "This approach shows how prompt tuning can be applied to enhance the T5 model's performance by training additional input embeddings while keeping the main model weights fixed.\n"
      ],
      "metadata": {
        "id": "uj5IIBTjyNSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary library if not already installed\n",
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "\n",
        "# Freeze the model weights to train only the soft prompts\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Create trainable soft prompt embeddings\n",
        "soft_prompt_length = 20  # Length of the soft prompt\n",
        "embedding_size = model.config.d_model  # Size of the model's hidden state\n",
        "soft_prompts = nn.Parameter(torch.randn(soft_prompt_length, embedding_size, requires_grad=True))\n",
        "\n",
        "# Initialize the optimizer for soft prompts\n",
        "optimizer = torch.optim.Adam([soft_prompts], lr=1e-3)\n",
        "\n",
        "# Create the training data from the DataFrame\n",
        "training_data = list(zip(selected_df['Text'], selected_df['Summary']))\n",
        "\n",
        "# Training loop for 2 epochs\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for input_text, target_summary in training_data:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Prepare inputs and outputs\n",
        "        input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "        target_ids = tokenizer.encode(target_summary, return_tensors=\"pt\", truncation=True, max_length=50)\n",
        "\n",
        "        # Combine soft prompts with input\n",
        "        prompt_tensor = soft_prompts.unsqueeze(0)\n",
        "        input_tensor = torch.cat((prompt_tensor, model.get_input_embeddings()(input_ids)), dim=1)\n",
        "\n",
        "        # Forward pass and loss computation\n",
        "        outputs = model(inputs_embeds=input_tensor, labels=target_ids)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {total_loss/len(training_data):.4f}\")\n",
        "\n",
        "print(\"Training completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX9MeLGm-Emg",
        "outputId": "4be92936-ebf6-4594-918e-7f0f74476294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Epoch 1/2 - Loss: 4.8087\n",
            "Epoch 2/2 - Loss: 4.2239\n",
            "Training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a summary with the trained soft prompts\n",
        "def generate_with_soft_prompt(text):\n",
        "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "    # Combine the trained soft prompts with the input embeddings\n",
        "    prompt_tensor = soft_prompts.unsqueeze(0)  # Add batch dimension\n",
        "    input_tensor = torch.cat((prompt_tensor, model.get_input_embeddings()(input_ids)), dim=1)\n",
        "\n",
        "    # Generate the output\n",
        "    outputs = model.generate(inputs_embeds=input_tensor, max_length=50, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Get the first item from the 'Text' column\n",
        "first_text = selected_df['Text'].iloc[0]\n",
        "\n",
        "# Generate a summary for the first item\n",
        "generated_summary = generate_with_soft_prompt(first_text)\n",
        "\n",
        "# Print the original text, original summary, and generated summary\n",
        "print(\"Original Text:\\n\", first_text)\n",
        "print(\"\\nGenerated Summary with Trained Soft Prompts:\\n\", generated_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvPAnAiF-EgY",
        "outputId": "1d0dfa69-1867-4c5e-ebb5-6edc61d28f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " These are actually very tasty.  Pure potatoes with a great texture and no nasty filler \"stuff.\"  No bacon, no cheese...just tasty potatoes.  They cook well in either the oven or microwave.  I add a touch of either salt & pepper or fajita seasoning to spice it up.  I rated 4 out of 5 stars because they could be a bit bigger portion.  However, this item is a fairly good value for the money.\n",
            "\n",
            "Generated Summary with Trained Soft Prompts:\n",
            " These are really tasty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UngxSBA65Qt6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  PEFT (Parameter-Efficient Fine-Tuning)\n"
      ],
      "metadata": {
        "id": "yekmZcJj12bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "G6nTVtPJ12Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import get_peft_model, LoraConfig"
      ],
      "metadata": {
        "id": "7-Dig3HW5wN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AMB7UQQTHePd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying LoRA (Low-Rank Adaptation) for Model Fine-Tuning\n",
        "\n",
        "This cell sets up and applies a LoRA (Low-Rank Adaptation) configuration to the T5 model to enable efficient fine-tuning. Here is what each part of the code does:\n",
        "\n",
        "- **LoRA Configuration (`LoraConfig`)**:\n",
        "  - **`r`**: Specifies the rank for the low-rank adaptation. This parameter controls the dimensionality of the low-rank matrices applied to the model. A higher value may improve model capacity but can also increase computation.\n",
        "  - **`lora_alpha`**: A scaling factor for the low-rank matrices, influencing the learning rate adjustment for these layers.\n",
        "  - **`lora_dropout`**: Specifies the dropout rate applied during training to prevent overfitting.\n",
        "  - **`target_modules`**: Indicates the specific model layers where LoRA will be applied. For T5, \"q\" and \"v\" represent the query and value layers of the attention mechanism, which are common targets for LoRA in transformer models.\n",
        "  - **`bias`**: Set to `\"none\"` to exclude bias terms from the LoRA layers, simplifying the adaptation.\n",
        "\n",
        "- **Applying the PEFT Model**:\n",
        "  - The `get_peft_model()` function takes the original T5 model and the configured `lora_config` and applies LoRA to the specified layers. This enhances the model's training efficiency by adding lightweight, trainable low-rank matrices without modifying the core model weights.\n",
        "\n",
        "This approach is useful for adapting pre-trained models to new tasks with minimal computational overhead, allowing for faster and more efficient fine-tuning while preserving most of the pre-trained model's knowledge.\n"
      ],
      "metadata": {
        "id": "vE21tJycHfuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set LoRA configuration for fine-tuning\n",
        "lora_config = LoraConfig(\n",
        "    r=8,  # Rank for low-rank adaptation (adjust based on performance)\n",
        "    lora_alpha=32,  # Scaling factor for the low-rank matrices\n",
        "    lora_dropout=0.1,  # Dropout rate during training\n",
        "    target_modules=[\"q\", \"v\"],  # Target modules to apply LoRA (for T5, 'q' and 'v' refer to attention layers)\n",
        "\n",
        ")\n",
        "\n",
        "# Apply the PEFT model (LoRA)\n",
        "peft_model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "id": "2QpHmIRg4xKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=selected_df"
      ],
      "metadata": {
        "id": "B6crqXthSE-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the tokenizer and model\n",
        "model_name = \"t5-small\"  # You can use \"t5-base\" or \"t5-large\" for better quality\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "WmYD9vBTT_BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load the trained model and tokenizer\n",
        "model_name = '/content/drive/MyDrive/model_t5_summarization'  # Ensure this is the correct path\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Now you can proceed to summarize"
      ],
      "metadata": {
        "id": "94fo9YQCBxyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Load the trained model and tokenizer again if not in the same session\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load the model and tokenizer if necessary\n",
        "# Replace 'path/to/model' with the actual path if the model needs to be reloaded\n",
        "# model = T5ForConditionalGeneration.from_pretrained('path/to/model')\n",
        "# tokenizer = T5Tokenizer.from_pretrained('path/to/model')\n",
        "\n",
        "# Input your specific review and summary\n",
        "input_text = \"These are actually very tasty. Pure potatoes with a great texture and no nasty filler 'stuff.' No bacon, no cheese...just tasty potatoes. They cook well in either the oven or microwave. I add a touch of either salt & pepper or fajita seasoning to spice it up. I rated 4 out of 5 stars because they could be a bit bigger portion. However, this item is a fairly good value for the money.\"\n",
        "original_summary = \"I like these\"\n",
        "\n",
        "# Prepare the input for the model\n",
        "input_enc = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# Move the input tensor to the same device as the model (e.g., GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "input_enc = {key: val.to(device) for key, val in input_enc.items()}\n",
        "\n",
        "# Generate the summary\n",
        "summary_ids = model.generate(\n",
        "    input_enc['input_ids'],\n",
        "    max_length=50,  # Adjust as needed\n",
        "    min_length=25,  # Adjust as needed\n",
        "    length_penalty=2.0,\n",
        "    num_beams=4,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "# Decode the summary\n",
        "predicted_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the results\n",
        "print(\"Original Review:\", input_text)\n",
        "print(\"Original Summary:\", original_summary)\n",
        "print(\"Predicted Summary:\", predicted_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cyv1jJBAJYc",
        "outputId": "25948328-5861-44bd-965a-132ad23b0647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Review: These are actually very tasty. Pure potatoes with a great texture and no nasty filler 'stuff.' No bacon, no cheese...just tasty potatoes. They cook well in either the oven or microwave. I add a touch of either salt & pepper or fajita seasoning to spice it up. I rated 4 out of 5 stars because they could be a bit bigger portion. However, this item is a fairly good value for the money.\n",
            "Original Summary: I like these\n",
            "Predicted Summary: I rated them 4 out of 5 stars because they could be a bit bigger than a bit larger.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG for Summarization"
      ],
      "metadata": {
        "id": "7wlJKdjWVSzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVIr9MPXV9eP",
        "outputId": "7e22754d-e259-4dda-8273-64095c3b39ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install faiss-cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kMb8Ci9V_iY",
        "outputId": "bd86d465-083d-44aa-fcb5-2375bc8df0a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarizing Text Using a Pre-trained T5 Model\n",
        "\n",
        "This cell demonstrates how to use a pre-trained T5 model for generating summaries from input text. Below is a breakdown of the code:\n",
        "\n",
        "- **Library Installation**:\n",
        "  - Installs the `transformers` library to ensure that all necessary components for working with the T5 model are available.\n",
        "\n",
        "- **Model and Tokenizer Loading**:\n",
        "  - Loads the `t5-small` tokenizer and model using `T5Tokenizer.from_pretrained()` and `T5ForConditionalGeneration.from_pretrained()`. Users can swap `t5-small` with `t5-base` or `t5-large` for potentially better summarization quality.\n",
        "\n",
        "- **Function for Generating Summaries**:\n",
        "  - A function `generate_t5_summary` is defined to:\n",
        "    - Accept an input text.\n",
        "    - Prepend the input with \"summarize:\" as a prompt for the T5 model.\n",
        "    - Encode the input text with truncation and a maximum length of 512 tokens.\n",
        "    - Generate a summary using the model with specified parameters such as `max_length`, `min_length`, `length_penalty`, `num_beams`, and `early_stopping` for better control over output quality.\n",
        "    - Decode and return the generated summary, excluding special tokens for readability.\n",
        "\n",
        "- **Generating and Displaying a Summary**:\n",
        "  - The first entry from the `Text` column of `selected_df` is selected for summarization.\n",
        "  - The function `generate_t5_summary` is called to generate a summary for the selected text.\n",
        "  - The original text and the generated summary are printed to compare and evaluate the model's performance.\n",
        "\n",
        "This step helps illustrate the practical use of T5 for generating concise and meaningful summaries from longer pieces of text.\n"
      ],
      "metadata": {
        "id": "0op4ZLnaz8w9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary library if not already installed\n",
        "!pip install transformers\n",
        "\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load pre-trained T5 model and tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')  # You can use 't5-base' or 't5-large' for better results\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "\n",
        "# Function to summarize a single text\n",
        "def generate_t5_summary(text, max_length=50, min_length=25):\n",
        "    # Prepare the input by adding the prompt\n",
        "    input_text = \"summarize: \" + text\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "    # Generate the summary\n",
        "    summary_ids = model.generate(input_ids, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Get the first item from the 'Text' column of selected_df\n",
        "first_text = selected_df['Text'].iloc[0]  # Ensure selected_df is defined\n",
        "\n",
        "# Generate a summary for the first item\n",
        "generated_summary = generate_t5_summary(first_text)\n",
        "\n",
        "# Print the original text and the generated summary\n",
        "print(\"Original Text:\\n\", first_text)\n",
        "print(\"\\nGenerated Summary using T5:\\n\", generated_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_JVqDOWU5Bf",
        "outputId": "09adb9c2-acfe-4fbb-c0ef-46cf4f96cb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Original Text:\n",
            " These are actually very tasty.  Pure potatoes with a great texture and no nasty filler \"stuff.\"  No bacon, no cheese...just tasty potatoes.  They cook well in either the oven or microwave.  I add a touch of either salt & pepper or fajita seasoning to spice it up.  I rated 4 out of 5 stars because they could be a bit bigger portion.  However, this item is a fairly good value for the money.\n",
            "\n",
            "Generated Summary using T5:\n",
            " pure potatoes with a great texture and no nasty filler \"stuff\" they cook well in either the oven or microwave. this item is a fairly good value for money.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ejngDKXXQCZT",
        "outputId": "4875352b-2660-457d-8336-d2a15207f04f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Simple Retrieval-Augmented Generation (RAG) System\n",
        "\n",
        "This cell demonstrates how to build a basic Retrieval-Augmented Generation (RAG) system using a combination of FAISS for document retrieval and a pre-trained T5 model for response generation. Below is a breakdown of each step:\n",
        "\n",
        "- **Library Imports**:\n",
        "  - `pandas` for handling data in a DataFrame format.\n",
        "  - `faiss` for creating a vector index to support efficient document retrieval.\n",
        "  - `numpy` for array manipulations.\n",
        "  - `T5Tokenizer` and `T5ForConditionalGeneration` from `transformers` for text generation.\n",
        "  - `TfidfVectorizer` from `sklearn.feature_extraction.text` for creating text vector embeddings.\n",
        "\n",
        "- **Sample Text Preparation**:\n",
        "  - A sample text is used to create a small dataset (`selected_df`) with a column for the text and a corresponding summary. In practice, this would be replaced by a larger dataset.\n",
        "\n",
        "- **Step 1: Vector Embeddings and FAISS Index Creation**:\n",
        "  - The `TfidfVectorizer` converts the text documents into vector embeddings.\n",
        "  - A FAISS index (`IndexFlatL2`) is created and populated with these embeddings to allow for efficient similarity searches.\n",
        "  - The index is saved to disk for later use.\n",
        "\n",
        "- **Step 2: Loading the T5 Model and Tokenizer**:\n",
        "  - The `t5-small` tokenizer and model are loaded for generating text responses.\n",
        "\n",
        "- **Step 3: Function to Retrieve Relevant Documents and Generate a Response**:\n",
        "  - The `generate_rag_response` function retrieves relevant documents based on a query:\n",
        "    - Loads the saved FAISS index and creates an embedding for the query.\n",
        "    - Searches the index to retrieve the most similar documents.\n",
        "    - Combines the retrieved documents and the query as input for the T5 model.\n",
        "    - Generates a response by summarizing the combined input and returns the output.\n",
        "    \n",
        "- **Step 4: Testing the Function**:\n",
        "  - The function is tested using the original text as the query to generate a response, showcasing how the RAG system performs.\n",
        "\n",
        "This cell provides a basic implementation of a RAG system that can be extended for more complex applications, such as question answering or document summarization.\n"
      ],
      "metadata": {
        "id": "2gBqJ9xxYsSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import faiss\n",
        "import numpy as np\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Sample text for testing\n",
        "original_text = \"\"\"These are actually very tasty. Pure potatoes with a great texture and no nasty filler 'stuff.'\n",
        "No bacon, no cheese...just tasty potatoes. They cook well in either the oven or microwave. I add a touch of either\n",
        "salt & pepper or fajita seasoning to spice it up. I rated 4 out of 5 stars because they could be a bit bigger portion.\n",
        "However, this item is a fairly good value for the money.\"\"\"\n",
        "\n",
        "# Prepare the dataset (in practice, use a full dataset as shown before)\n",
        "data = {\n",
        "    'Text': [original_text],\n",
        "    'Summary': [\"I like these!\"]  # Original summary, just for context\n",
        "}\n",
        "selected_df = pd.DataFrame(data)\n",
        "\n",
        "# Step 1: Create vector embeddings and FAISS index\n",
        "documents = selected_df['Text'].tolist()\n",
        "vectorizer = TfidfVectorizer().fit(documents)\n",
        "document_embeddings = vectorizer.transform(documents).toarray()\n",
        "\n",
        "dimension = document_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(document_embeddings.astype(np.float32))\n",
        "\n",
        "# Save the FAISS index to disk\n",
        "faiss.write_index(index, \"text_vector_index.faiss\")\n",
        "\n",
        "# Step 2: Load the T5 model and tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "\n",
        "# Step 3: Function to retrieve relevant documents and generate a response\n",
        "def generate_rag_response(query, num_retrieved_docs=1):\n",
        "    # Load the saved FAISS index\n",
        "    index = faiss.read_index(\"text_vector_index.faiss\")\n",
        "\n",
        "    # Create an embedding for the query\n",
        "    query_embedding = vectorizer.transform([query]).toarray().astype(np.float32)\n",
        "    distances, indices = index.search(query_embedding, num_retrieved_docs)\n",
        "\n",
        "    # Retrieve relevant documents\n",
        "    retrieved_docs = [documents[i] for i in indices[0]]\n",
        "    combined_input = \" \".join(retrieved_docs) + \" \" + query\n",
        "\n",
        "    # Prepare input for T5\n",
        "    input_text = \"summarize: \" + combined_input\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "    # Generate the response\n",
        "    summary_ids = model.generate(input_ids, max_length=50, min_length=25, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Step 4: Test the function with the original text\n",
        "query = original_text  # Use the original text as the query\n",
        "response = generate_rag_response(query)\n",
        "print(\"\\nGenerated Summary:\\n\", response)\n"
      ],
      "metadata": {
        "id": "OCiKeut6Ai6g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1163e704-854c-47c1-e49c-b5786352ceb9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Summary:\n",
            " Pure potatoes with a great texture and no nasty filler'stuff' they cook well in either the oven or microwave. I add a touch of either salt & pepper or fajita seasoning to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<style>\n",
        "  table {\n",
        "    width: 100%;\n",
        "    border-collapse: collapse;\n",
        "    margin: 20px 0;\n",
        "  }\n",
        "  th, td {\n",
        "    padding: 15px;\n",
        "    text-align: left;\n",
        "    border-bottom: 1px solid #ddd;\n",
        "  }\n",
        "  th {\n",
        "    background-color: #f4f4f4;\n",
        "    font-weight: bold;\n",
        "  }\n",
        "  tr:first-child th {\n",
        "    border-top: 2px solid #000;\n",
        "  }\n",
        "  hr {\n",
        "    border: 1px solid #ddd;\n",
        "    margin: 0;\n",
        "  }\n",
        "  td {\n",
        "    word-wrap: break-word;\n",
        "  }\n",
        "</style>\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Original Text</th>\n",
        "    <td>These are actually very tasty.  Pure potatoes with a great texture and no nasty filler 'stuff.'  No bacon, no cheese...just tasty potatoes.  They cook well in either the oven or microwave.  I add a touch of either salt & pepper or fajita seasoning to spice it up.  I rated 4 out of 5 stars because they could be a bit bigger portion.  However, this item is a fairly good value for the money.</td>\n",
        "  </tr>\n",
        "  <hr>\n",
        "  <tr>\n",
        "    <th>Original Summary</th>\n",
        "    <td>I like these!</td>\n",
        "  </tr>\n",
        "  <hr>\n",
        "  <tr>\n",
        "    <th>Generated Summary with Prompt Engineering</th>\n",
        "    <td>pure potatoes with a great texture and no nasty filler 'stuff' they cook well in either the oven or microwave. this item is a fairly good value for money.</td>\n",
        "  </tr>\n",
        "  <hr>\n",
        "  <tr>\n",
        "    <th>Generated Summary with Trained Soft Prompts</th>\n",
        "    <td>These are really tasty.</td>\n",
        "  </tr>\n",
        "  <hr>\n",
        "  <tr>\n",
        "    <th>Predicted Summary with LoRA PEFT</th>\n",
        "    <td>I rated them 4 out of 5 stars because they could be a bit bigger than a bit larger.</td>\n",
        "  </tr>\n",
        "  <hr>\n",
        "  <tr>\n",
        "    <th>Generated Summary using T5 RAG</th>\n",
        "    <td> Pure potatoes with a great texture and no nasty filler'stuff' they cook well in either the oven or microwave. I add a touch of either salt & pepper or fajita seasoning to</td>\n",
        "  </tr>\n",
        "</table>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "ArgJtq0iAfrH",
        "outputId": "e0b1e7c4-7281-4ebe-ea66-f0da100238cd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "  table {\n",
              "    width: 100%;\n",
              "    border-collapse: collapse;\n",
              "    margin: 20px 0;\n",
              "  }\n",
              "  th, td {\n",
              "    padding: 15px;\n",
              "    text-align: left;\n",
              "    border-bottom: 1px solid #ddd;\n",
              "  }\n",
              "  th {\n",
              "    background-color: #f4f4f4;\n",
              "    font-weight: bold;\n",
              "  }\n",
              "  tr:first-child th {\n",
              "    border-top: 2px solid #000;\n",
              "  }\n",
              "  hr {\n",
              "    border: 1px solid #ddd;\n",
              "    margin: 0;\n",
              "  }\n",
              "  td {\n",
              "    word-wrap: break-word;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "<table>\n",
              "  <tr>\n",
              "    <th>Original Text</th>\n",
              "    <td>These are actually very tasty.  Pure potatoes with a great texture and no nasty filler 'stuff.'  No bacon, no cheese...just tasty potatoes.  They cook well in either the oven or microwave.  I add a touch of either salt & pepper or fajita seasoning to spice it up.  I rated 4 out of 5 stars because they could be a bit bigger portion.  However, this item is a fairly good value for the money.</td>\n",
              "  </tr>\n",
              "  <hr>\n",
              "  <tr>\n",
              "    <th>Original Summary</th>\n",
              "    <td>I like these!</td>\n",
              "  </tr>\n",
              "  <hr>\n",
              "  <tr>\n",
              "    <th>Generated Summary with Prompt Engineering</th>\n",
              "    <td>pure potatoes with a great texture and no nasty filler 'stuff' they cook well in either the oven or microwave. this item is a fairly good value for money.</td>\n",
              "  </tr>\n",
              "  <hr>\n",
              "  <tr>\n",
              "    <th>Generated Summary with Trained Soft Prompts</th>\n",
              "    <td>These are really tasty.</td>\n",
              "  </tr>\n",
              "  <hr>\n",
              "  <tr>\n",
              "    <th>Predicted Summary with LoRA PEFT</th>\n",
              "    <td>I rated them 4 out of 5 stars because they could be a bit bigger than a bit larger.</td>\n",
              "  </tr>\n",
              "  <hr>\n",
              "  <tr>\n",
              "    <th>Generated Summary using T5 RAG</th>\n",
              "    <td> Pure potatoes with a great texture and no nasty filler'stuff' they cook well in either the oven or microwave. I add a touch of either salt & pepper or fajita seasoning to</td>\n",
              "  </tr>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YhMavb3uU47H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PX4yx_h40vLb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}